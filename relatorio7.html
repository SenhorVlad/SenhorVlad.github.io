<!DOCTYPE html>
<html>
<head>
  <title>Relatório</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.2/css/bootstrap.min.css">
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
    }
    h1 {
      color: #333;
    }
    p {
      color: #666;
    }
    pre {
      background-color: #f8f8f8;
      padding: 10px;
      overflow-x: auto;
    }
    .navbar {
      background-color: rgb(0,90,60);
      padding: 10px;
      color: #fff;
      display: flex;
      align-items: center;
    }
    .logo {
      width: 50px;
      margin-right: 10px;
    }
    .title {
      font-weight: bold;
      font-size: 18px;
    }
    .imgs {
      display: flex;
      justify-content: center;
      align-items: center;
    }
    .imgs img {
      max-width: 100%;
      max-height: 400px;
      margin: 10px;
    }
    .video {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 50%;
      height: 400px;
    }
    .video video {
      max-width: 100%;
      max-height: 100%;
    }
  </style>
</head>
<body>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <div class="container-fluid">
      <a class="navbar-brand" href="index.html">
        <img src="ufabc_logo.png" alt="UFABC Logo" class="logo">
        <span class="title">Processamento de Vídeo</span>
      </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNav">
        <ul class="navbar-nav">
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="relatoriosDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
              Relatórios
            </a>
            <ul class="dropdown-menu" aria-labelledby="relatoriosDropdown">
              <li><a class="dropdown-item" href="relatorio1.html">Relatório 1</a></li>
              <li><a class="dropdown-item" href="relatorio2.html">Relatório 2</a></li>
              <li><a class="dropdown-item" href="relatorio3.html">Relatório 3</a></li>
              <li><a class="dropdown-item" href="relatorio4.html">Relatório 4</a></li>
              <li><a class="dropdown-item" href="relatorio5.html">Relatório 5</a></li>
              <li><a class="dropdown-item" href="relatorio6.html">Relatório 6</a></li>
              <li><a class="dropdown-item" href="relatorio7.html">Relatório 7</a></li>
              <li><a class="dropdown-item" href="relatorio8.html">Relatório 8</a></li>
            </ul>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="projfinal.html">Projeto Final</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="integrantesDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
              Integrantes
            </a>
            <ul class="dropdown-menu" aria-labelledby="integrantesDropdown">
              <li><a class="dropdown-item" href="Fernando.html">Fernando Cezar Resende Lopes</a></li>
              <li><a class="dropdown-item" href="Muriel.html">Muriel da Costa Santos</a></li>
              <li><a class="dropdown-item" href="Vinicius.html">Vinicius de Souza</a></li>
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  <div class="container"><p></p>
    <h1 class="text-center">Laboratório 7 – Detecção de Objetos</h1>
    <p><strong>(1)</strong>Desenvolva programas para fazer a leitura de sua imagem geral dos membros da equipe e da imagem com avatares.</p><p>
      --utilize as imagens do seu trabalho de video.</p>
      
      <p>O programa deve realizar a detecção de objetos e apresentar na tela. Obs.: escolha cores contrastantes na identificação.
      </p><p>
      Faça mais de uma versão do programa, sendo pelo menos uma versão com modelos XML Haarcascade dos exercícios acima, e outra versão com modelo XML Haarcascade que não foi usado nos exercícios.
      </p>
      <p>O programa também deve salvar as imagens com identificação dos Objetos, ao toque de uma tecla.</p>
      <strong>lab7FacesDoGrupo</strong>
    <pre><code>import cv2 
      import numpy as np 
      import common #some useful opencv functions
      
      test_image = cv2.imread('grupo.jpeg')
      grey = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
      
      # Carrega a cascade treinada e na imagem cinza aplica Detecção de FACES:
      face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
      faces = face_cascade.detectMultiScale(grey, 1.3, 5)
      
      # Carrega a cascade treinada e na imagem cinza aplica Detecção de SORRISOS:
      smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')
      smiles = smile_cascade.detectMultiScale(grey, 1.3, 20)
      
      # na imagem de entrada desenha retangulos nos pontos detectados
      for (x,y,w,h) in smiles:
           cv2.rectangle(test_image,(x,y),(x+w,y+h),(255,255,0),2)
           
      # Definir nome da janela para re-dimensionar a janela
      height, width, ch = test_image.shape
      W2 = int(width/2)
      H2 = int(height/2)
      cv2.namedWindow("All Smiles", cv2.WINDOW_NORMAL)
      cv2.resizeWindow("All Smiles", W2, H2)
      cv2.imshow("All Smiles", test_image)
      
      # Restringir Sorrisos dentro das Faces
      test_image = cv2.imread('grupo.jpeg')
      for (x,y,w,h) in faces:
        for (x_s,y_s,w_s,h_s) in smiles:
          if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):
            cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(255,255,0),2)
      
      cv2.namedWindow("Smiles of Faces Only", cv2.WINDOW_NORMAL)
      cv2.resizeWindow("Smiles of Faces Only", W2, H2)
      cv2.imshow("Smiles of Faces Only", test_image)
      
      if cv2.waitKey(0) & 0xff == 27:
       cv2.destroyAllWindows()
      
      </code></pre>
      <p>O código utiliza OpenCV para detectar faces e sorrisos em uma imagem. Ele carrega uma imagem chamada "grupo.jpeg", converte-a para tons de cinza e aplica dois classificadores em cascata pré-treinados: um para detectar faces e outro para detectar sorrisos. Em seguida, desenha retângulos azuis em torno dos sorrisos encontrados na imagem original e também em torno dos sorrisos que estão dentro de uma região de face. As imagens resultantes são mostradas em janelas redimensionadas e o código espera por uma tecla para ser pressionada antes de fechar as janelas.</p>
    <div class="center-content">
        <img src="r7i1.png" alt="r7i1" width="50%">
    </div><p></p>
    <strong>lab7FacesDosAvatares</strong>
    <pre><code>import cv2 
      import numpy as np 
      import common #some useful opencv functions
      
      test_image = cv2.imread('avatares.jpeg')
      grey = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
      
      # Carrega a cascade treinada e na imagem cinza aplica Detecção de FACES:
      face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
      faces = face_cascade.detectMultiScale(grey, 1.3, 5)
      
      # Carrega a cascade treinada e na imagem cinza aplica Detecção de SORRISOS:
      smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')
      smiles = smile_cascade.detectMultiScale(grey, 1.3, 20)
      
      # na imagem de entrada desenha retangulos nos pontos detectados
      for (x,y,w,h) in smiles:
           cv2.rectangle(test_image,(x,y),(x+w,y+h),(255,255,0),2)
           
      # Definir nome da janela para re-dimensionar a janela
      height, width, ch = test_image.shape
      W2 = int(width/2)
      H2 = int(height/2)
      cv2.namedWindow("All Smiles", cv2.WINDOW_NORMAL)
      cv2.resizeWindow("All Smiles", W2, H2)
      cv2.imshow("All Smiles", test_image)
      
      # Restringir Sorrisos dentro das Faces
      test_image = cv2.imread('avatares.jpeg')
      for (x,y,w,h) in faces:
        for (x_s,y_s,w_s,h_s) in smiles:
          if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):
            cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(255,255,0),2)
      
      cv2.namedWindow("Smiles of Faces Only", cv2.WINDOW_NORMAL)
      cv2.resizeWindow("Smiles of Faces Only", W2, H2)
      cv2.imshow("Smiles of Faces Only", test_image)
      
      if cv2.waitKey(0) & 0xff == 27:
       cv2.destroyAllWindows()
      </code></pre>
      <p>O código utiliza a biblioteca OpenCV em Python para detectar faces e sorrisos em uma imagem chamada "avatares.jpeg". Ele converte a imagem para tons de cinza e aplica dois classificadores em cascata pré-treinados: um para detectar faces e outro para detectar sorrisos. Os sorrisos detectados são realçados com retângulos azuis na imagem original. Além disso, os sorrisos que estão completamente contidos em uma região de face também são realçados. As imagens resultantes são mostradas em janelas redimensionadas e o código espera por uma tecla para ser pressionada antes de fechar as janelas.</p>
</body>
    <div class="center-content">
        <img src="r7i2.png" alt="r7i2" width="50%">
    </div><p></p>
    <p><strong>(2)</strong>Outro programa modificando o item (1), agora fazendo a leitura de imagem da webcam.</p>
      <p>Neste caso, o programa deve adicionalmente mostrar uma janela ao vivo com a imagem e o resultado da identificação do objeto.</p>
      <p>Realize este experimento com um modelo XML. Salvar a imagem ao toque de uma tecla.</p>
    <pre><code>import cv2 
      import numpy as np 
      import common #some useful opencv functions
      cap = cv2.VideoCapture(0)
      
      videoSaida = 'videoRastreadolho.avi'
      
      largura = 640
      altura = 480
      fps = 30.0
      codec = cv2.VideoWriter_fourcc(*'XVID')
      out = cv2.VideoWriter(videoSaida, codec, fps, (largura, altura))
      
      
      while True:
          ret, test_image = cap.read()
          if not ret:
              print("Can't receive frame (stream end?). Exiting ...")
              break
          grey = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
      
        # Carrega a cascade treinada e na imagem cinza aplica Detecção de FACES:
          face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
          faces = face_cascade.detectMultiScale(grey, 1.3, 5)
      
        # Carrega a cascade treinada e na imagem cinza aplica Detecção de SORRISOS:
          smile_cascade = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')
          smiles = smile_cascade.detectMultiScale(grey, 1.3, 20)
          cv2.imshow("Original", test_image)
        # na imagem de entrada desenha retangulos nos pontos detectados
          for (x,y,w,h) in smiles:
              cv2.rectangle(test_image,(x,y),(x+w,y+h),(0,255,0),2)
             
        # Definir nome da janela para re-dimensionar a janela
              height, width, ch = test_image.shape
              W2 = int(width/2)
              H2 = int(height/2)
              cv2.namedWindow("Original", cv2.WINDOW_NORMAL)
              cv2.resizeWindow("Original", W2, H2)
          out.write(test_image)
      
        # Restringir Sorrisos dentro das Faces
          for (x,y,w,h) in faces:
              for (x_s,y_s,w_s,h_s) in smiles:
                  if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):
                      cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(0,255,0),2)
      
          cv2.namedWindow("Eye Followed", cv2.WINDOW_NORMAL)
          height, width, ch = test_image.shape
          W2 = int(width/2)
          H2 = int(height/2)
          cv2.resizeWindow("Eyes Followed", W2, H2)
          cv2.imshow("Eye Followed", test_image)
      
          if cv2.waitKey(1) & 0xff == 27:
              if key == ord('q'):
                  break
      
      cv2.destroyAllWindows()
      cap.release()
      </code></pre>
      <p>O código utiliza a biblioteca OpenCV em Python para realizar o rastreamento dos olhos em um vídeo capturado pela câmera. Ele configura a captura de vídeo a partir da câmera (dispositivo 0) e define as configurações do vídeo de saída. O programa entra em um loop infinito, onde cada frame do vídeo é lido e processado.</p>
      <p>Primeiro, converte o frame para tons de cinza e, em seguida, utiliza um classificador em cascata pré-treinado para detectar faces e outro para detectar olhos. Os olhos detectados são realçados com retângulos verdes na imagem original, enquanto os olhos que estão dentro de uma região de face também são realçados.</p>
      <p>O vídeo resultante é salvo em "videoRastreadolho.avi" e também é mostrado em uma janela chamada "Eye Followed". O código aguarda por uma tecla para ser pressionada, e caso a tecla 'q' ou a tecla "ESC" (código 27) sejam pressionadas, o loop é interrompido, e as janelas são fechadas, finalizando a execução do programa.</p>
      <div class="embed-responsive embed-responsive-16by9" style="display: flex; flex-direction: column; align-items: center;">
        <video class="embed-responsive-item" src="r7v1.mp4" controls></video>
        <p class="figcaption">Rastreamento de olho</p>
      </div>
  </div>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.2/js/bootstrap.bundle.min.js"></script>
</body>
</html>
